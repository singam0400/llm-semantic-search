# ğŸ§  LLM Semantic Search + QA with SBERT & DistilBERT

A compact, production-inspired **semantic search + question answering** system using **Sentence-BERT for dense retrieval** and **DistilBERT for local extractive QA**. 

---

## ğŸš€ What This Project Does

> Upload a `.txt` file â†’ Ask a natural language question â†’ Get an intelligent answer using local models.

âœ… Sentence-BERT (`MiniLM-L6-v2`) generates dense embeddings  
âœ… Custom cosine similarity returns top semantic matches  
âœ… DistilBERT (SQuAD fine-tuned) generates an answer from top-k retrieved chunks  

---

## ğŸ§© Tech Stack

| Layer                | Component                              |
|----------------------|-----------------------------------------|
| ğŸ” Embedding Model   | `sentence-transformers/paraphrase-MiniLM-L6-v2` |
| ğŸ“š Search Engine     | NumPy-based cosine similarity            |
| ğŸ§  QA Model          | `distilbert-base-cased-distilled-squad` |
| âš™ï¸ Interface         | Google Colab (`.ipynb`)                  |
| ğŸ§° Utils             | Modular Python file (`utils.py`)         |

---

## ğŸ”® Potential Extensions

- Swap QA model with **open-weight LLM** like Mistral or TinyLlama  /  
- Support **multi-document RAG with citations**    
- Replace NumPy similarity with **FAISS or ChromaDB** for large-scale corpora

---
